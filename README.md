A_Rapid_Prototyping_Framework_for_Human_Robot_Interaction 


Many current human-robot interactive systems tend to use accurate and fast, but also costly actuators
and tracking systems to establish working prototypes that are safe to use and deploy for user studies.
This work presents an embedded framework to build a desktop space for human-robot interaction, using 
an open-design robot arm, as well as two RGB cameras connected to a Raspberry Pi-based controller that 
allow a fast yet low-cost object tracking and manipulation in 3D. Results show that this facilitates
prototyping a number of systems in which user and robot arm can commonly interact with physical objects.

This work presents a embedded framework for human-robot interaction to allow robotics enthusiasts and researchers
to develop low-cost and rapid prototypes of robot arms, to test out project ideas for educational purposes or before
a full scale implementation. This report will show that the robot arm can autonomously and quickly locate any object(s)
at any position within its workspace, and can perform a specific (different) task depending on the id of the fiducial marker 
identified. Also, early stage development of the embedded framework is introduced and explained, experimental case studies and
performance results are presented. 

A video demostration is on youTube here https://youtu.be/wiNIN8MH4uc

system and source code description can be found here  A_Rapid_Prototyping_Framework_for_Human_Robot_Interaction.pdf




